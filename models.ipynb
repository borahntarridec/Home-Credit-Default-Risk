{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ PICLKE\n",
    "\n",
    "DATA_PATH = '../HomeCreditDefaultRisk/Data'\n",
    "train_df = pd.read_pickle(os.path.join(DATA_PATH,'train_df.p'))\n",
    "test_df = pd.read_pickle(os.path.join(DATA_PATH,'test_df.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "\n",
    "def kfold_lightgbm(train_df, test_df, num_folds, stratified = False):\n",
    "\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    gc.collect()\n",
    "\n",
    "    folds = KFold(n_splits= num_folds, shuffle=True, random_state=47)\n",
    "    \n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])    \n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    i=0\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "        i += 1\n",
    "        \n",
    "        # LightGBM parameters found by Bayesian optimization\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=4,\n",
    "            #is_unbalance=True,\n",
    "            n_estimators=10000,\n",
    "            learning_rate=0.02,\n",
    "            num_leaves=32,\n",
    "            colsample_bytree=0.9497036,\n",
    "            subsample=0.8715623,\n",
    "            max_depth=8,\n",
    "            reg_alpha=0.04,\n",
    "            reg_lambda=0.073,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=40,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "            scale_pos_weight=1\n",
    "            )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "            eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n",
    "        \n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        \n",
    "        print(\"n_splits\",folds.n_splits)\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        \n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "        \n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    # Write submission file and plot feature importance\n",
    "\n",
    "    test_df['TARGET'] = sub_preds\n",
    "    #test_df[['SK_ID_CURR', 'TARGET']].to_csv('submission.csv', index= False)\n",
    "    \n",
    "    \n",
    "    #display_importances(feature_importance_df)\n",
    "    return feature_importance_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (99997, 706), test shape: (48744, 706)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.784006\tvalid_1's auc: 0.751761\n",
      "[400]\ttraining's auc: 0.821585\tvalid_1's auc: 0.761441\n",
      "[600]\ttraining's auc: 0.843717\tvalid_1's auc: 0.762006\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's auc: 0.839032\tvalid_1's auc: 0.762231\n",
      "n_splits 5\n",
      "Fold  1 AUC : 0.762231\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.784886\tvalid_1's auc: 0.753989\n",
      "[400]\ttraining's auc: 0.820878\tvalid_1's auc: 0.764212\n",
      "[600]\ttraining's auc: 0.843411\tvalid_1's auc: 0.765741\n",
      "[800]\ttraining's auc: 0.860546\tvalid_1's auc: 0.765986\n",
      "Early stopping, best iteration is:\n",
      "[745]\ttraining's auc: 0.856134\tvalid_1's auc: 0.766015\n",
      "n_splits 5\n",
      "Fold  2 AUC : 0.766015\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.784174\tvalid_1's auc: 0.75658\n",
      "[400]\ttraining's auc: 0.819387\tvalid_1's auc: 0.765934\n",
      "[600]\ttraining's auc: 0.841314\tvalid_1's auc: 0.767988\n",
      "[800]\ttraining's auc: 0.859365\tvalid_1's auc: 0.768287\n",
      "Early stopping, best iteration is:\n",
      "[631]\ttraining's auc: 0.844541\tvalid_1's auc: 0.768536\n",
      "n_splits 5\n",
      "Fold  3 AUC : 0.768536\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.784862\tvalid_1's auc: 0.745291\n",
      "[400]\ttraining's auc: 0.820414\tvalid_1's auc: 0.755975\n",
      "[600]\ttraining's auc: 0.841403\tvalid_1's auc: 0.757938\n",
      "[800]\ttraining's auc: 0.85878\tvalid_1's auc: 0.759038\n",
      "[1000]\ttraining's auc: 0.873703\tvalid_1's auc: 0.759154\n",
      "[1200]\ttraining's auc: 0.885951\tvalid_1's auc: 0.759133\n",
      "Early stopping, best iteration is:\n",
      "[1150]\ttraining's auc: 0.883297\tvalid_1's auc: 0.759415\n",
      "n_splits 5\n",
      "Fold  4 AUC : 0.759415\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's auc: 0.785053\tvalid_1's auc: 0.748037\n",
      "[400]\ttraining's auc: 0.820657\tvalid_1's auc: 0.758535\n",
      "[600]\ttraining's auc: 0.84111\tvalid_1's auc: 0.760948\n",
      "[800]\ttraining's auc: 0.858135\tvalid_1's auc: 0.761452\n",
      "[1000]\ttraining's auc: 0.872292\tvalid_1's auc: 0.761165\n",
      "Early stopping, best iteration is:\n",
      "[822]\ttraining's auc: 0.859274\tvalid_1's auc: 0.761603\n",
      "n_splits 5\n",
      "Fold  5 AUC : 0.761603\n",
      "Full AUC score 0.763314\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df, test_df = kfold_lightgbm(train_df, test_df, 5, stratified = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTO CATBOOST \n",
    "\n",
    "# Initialize data\n",
    "cat_features = [0,1,2]\n",
    "train_data = [[\"a\",\"b\",1,4,5,6],[\"a\",\"b\",4,5,6,7],[\"c\",\"d\",30,40,50,60]]\n",
    "train_labels = [1,1,-1]\n",
    "test_data = [[\"a\",\"b\",2,4,6,8],[\"a\",\"d\",1,4,50,60]]\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=2, learning_rate=1, depth=10, loss_function='Logloss')\n",
    "# Fit model\n",
    "model.fit(train_data, train_labels, cat_features)\n",
    "# Get predicted classes\n",
    "preds_class = model.predict(test_data)\n",
    "# Get predicted probabilities for each class\n",
    "preds_proba = model.predict_proba(test_data)\n",
    "# Get predicted RawFormulaVal\n",
    "preds_raw = model.predict(test_data, prediction_type='RawFormulaVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
